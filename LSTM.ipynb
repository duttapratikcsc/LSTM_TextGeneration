{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cVv305IpFOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "39d4c486-6edb-4d83-8e4e-3060824228ea"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "# from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from random import random\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abejn2bUpN6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_Word(fp):\n",
        "    word = []\n",
        "    raw_text = open(fp).read().lower()\n",
        "    raw_text = raw_text.split(\"\\n\")\n",
        "    for row in raw_text:\n",
        "        temp = row.split(\" \")\n",
        "        for i in range(len(temp)):\n",
        "            word.append(temp[i])\n",
        "    word.append(\"\\n\")\n",
        "    print(\"Length of total word_list:-\", len(word))\n",
        "    return(word)\n",
        "\n",
        "#First create a set of all of the distinct words,\n",
        "# then creating a map of each word to a unique integer.\n",
        "def get_Word_dict(word_list):\n",
        "    uniq_word = sorted(list(set(word_list)))\n",
        "    uniqword_to_int = dict((c, i) for i, c in enumerate(uniq_word))\n",
        "    print(\"Total no. Words:- \", len(word_list))\n",
        "    print(\"Total no. of unique words:- \", len(uniq_word))\n",
        "    return(uniqword_to_int)\n",
        "\n",
        "def get_int_to_word(word_list):\n",
        "    uniq_word = sorted(list(set(word_list)))\n",
        "    int_to_word = dict((i, c) for i, c in enumerate(uniq_word))\n",
        "    return(int_to_word)\n",
        "\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "def Data_Preprocessing(fp, seq_no, word_dict):\n",
        "    datax = []\n",
        "    datay = []\n",
        "    \n",
        "    raw_text = open(fp).read().lower()\n",
        "    raw_text = raw_text.split(\"\\n\")\n",
        "    fdatax = open('data_input.csv', \"w\")\n",
        "    for row in raw_text:\n",
        "        temp = (row +\" \\n\").split(\" \")\n",
        "        for i in range(len(temp)-seq_no):\n",
        "            temp_word_int = []\n",
        "            temp_word = []\n",
        "            for index in range(0, seq_no):\n",
        "                temp_word.append(temp[i+index])\n",
        "                temp_word_int.append(word_dict[temp[i+index]])\n",
        "#                print(temp_word_int)\n",
        "            datax.append([temp_word_int])\n",
        "            print(temp_word, \",\", temp_word_int, file = fdatax)\n",
        "            datay.append([word_dict[temp[i+seq_no]]])\n",
        "    return(datax, datay)\n",
        "\n",
        "def get_initial_last_Word(fp, seq_no):\n",
        "    initial_word = []\n",
        "    last_word = []\n",
        "\n",
        "    raw_text = open(fp).readlines()\n",
        "    for row in raw_text:\n",
        "        temp= row.split(\" \")\n",
        "        temp_word = \"\"\n",
        "        for index in range(0, seq_no):\n",
        "            temp_word += temp[0+index]+\" \"\n",
        "        initial_word.append(temp_word.rstrip(\" \"))\n",
        "        last_word.append(temp[-1])\n",
        "    \n",
        "    dami = list(set(initial_word))\n",
        "    dx = [x.split(\" \") for x in dami]\n",
        "    return(dx, list(set(last_word)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgptRTXapTvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createModel(X,y):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(y.shape[1], activation='softmax'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy', 'binary_crossentropy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov9wGWeNpY8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(histories, key='binary_crossentropy'):\n",
        "  plt.figure(figsize=(16,10))\n",
        "\n",
        "  for name, history in histories:\n",
        "    val = plt.plot(history.epoch, history.history['val_'+key],'--', label=name.title()+' Val')\n",
        "    plt.plot(history.epoch, history.history[key], color=val[0].get_color(),label=name.title()+' Train')\n",
        "\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(key.replace('_',' ').title())\n",
        "  plt.legend()\n",
        "\n",
        "  plt.xlim([0,max(history.epoch)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri_4xOH9phYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06ffd33f-1398-4af6-dc0d-7fa981f7dd25"
      },
      "source": [
        "filename = 'class_3_p.csv'\n",
        "seq = 3\n",
        "fileN=open(\"generatedText.txt\",\"w\")\n",
        "total_words = get_Word(filename)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of total word_list:- 30874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hJ0U5DDpjcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "17c46623-5b80-4c9c-efc2-7ae40d0da858"
      },
      "source": [
        "word_dict = get_Word_dict(total_words)\n",
        "int_to_word = get_int_to_word(total_words)\n",
        "initial_word, last_word = get_initial_last_Word(filename, seq)\n",
        "#print(initial_word)\n",
        "datax, datay = Data_Preprocessing(filename, seq, word_dict)\n",
        "#print(datax, file=fileN)\n",
        "no_patterns = len(datax)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. Words:-  30874\n",
            "Total no. of unique words:-  1011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqX7vbgapoOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.reshape(datax, (no_patterns, seq, 1))\n",
        "X = X / float(len(set(total_words)))\n",
        "y = np_utils.to_categorical(datay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33IChxolqPoZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ff59f4e-b238-4488-e293-4fb88fbed131"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27600, 1011)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZseIVbCpp96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "outputId": "226db12d-34ff-45ec-f98a-4b506dc89be5"
      },
      "source": [
        "model=None\n",
        "model = createModel(X, y)\n",
        "histories=model.fit(X, y, epochs=4, batch_size=128)\n",
        "plot_history([('baseline', histories)])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_5 (LSTM)                (None, 3, 128)            66560     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 3, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1011)              130419    \n",
            "=================================================================\n",
            "Total params: 328,563\n",
            "Trainable params: 328,563\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/4\n",
            "27600/27600 [==============================] - 11s 397us/step - loss: 0.0061 - acc: 0.9990 - binary_crossentropy: 0.0061\n",
            "Epoch 2/4\n",
            "27600/27600 [==============================] - 9s 330us/step - loss: 0.0051 - acc: 0.9990 - binary_crossentropy: 0.0051\n",
            "Epoch 3/4\n",
            "27600/27600 [==============================] - 9s 333us/step - loss: 0.0050 - acc: 0.9990 - binary_crossentropy: 0.0050\n",
            "Epoch 4/4\n",
            "27600/27600 [==============================] - 9s 330us/step - loss: 0.0048 - acc: 0.9990 - binary_crossentropy: 0.0048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-63c393a80397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'baseline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-486ad4096828>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(histories, key)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' Val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_binary_crossentropy'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huMNJV_spth6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = np.random.randint(0, len(initial_word)-1)\n",
        "seed_text = initial_word[start]\n",
        "print(seed_text)\n",
        "seed = [word_dict[word] for word in seed_text]\n",
        "print(seed)\n",
        "generatedTextList= seed_text\n",
        "flag = True\n",
        "print(generatedTextList)\n",
        "count=0\n",
        "\n",
        "while (flag):\n",
        "    x = np.reshape(seed, (1, len(seed), 1))\n",
        "    x = x / float(len(set(total_words)))\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_to_word[index]\n",
        "    generatedTextList.append(result)\n",
        "    seq_in = [int_to_word[value] for value in seed]\n",
        "#         sys.stdout.write(result+ \" \")\n",
        "#         print(result+ \" \",end=\"\")\n",
        "    seed.append(index)\n",
        "    seed = seed[1:len(seed)]\n",
        "    if result == \"\\n\" or count==10:\n",
        "        flag = False\n",
        "    count+=1\n",
        "\n",
        "print(generatedTextList, file = fileN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsyU0ZvPukUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47ca58b9-ca68-4222-fe9d-ff152583b8a7"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "y = np.array([1, 2, 3, 4])\n",
        "kf = KFold(n_splits=2)\n",
        "kf.get_n_splits(X)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}